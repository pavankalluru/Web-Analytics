import pandas as pd
import numpy as np
import matplotlib

matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords

yelp = pd.read_csv('yelp.csv')

# some basic information about the data.

# print(yelp.shape )
# print(yelp.describe())

# adding length column to determine the length of text

yelp['text length'] = yelp['text'].apply(len)
print(yelp.head())

# Relation between Text length and stars column's using Seaborn library:
g = sns.FacetGrid(data=yelp, col='stars')
print(g.map(plt.hist, 'text length', bins=50))

# finding Correlation using Pandas

stars = yelp.groupby('stars').mean()
print(stars.corr())

# To visualise these correlations, we can use Seabornâ€™s heatmap:

print(sns.heatmap(data=stars.corr(), annot=True))

# New dataframe with reviews either 1 0r 5 star ratings from Yelp.

yelp_class = yelp[(yelp['stars'] == 1) | (yelp['stars'] == 5)]  # print(yelp_class.shape)

x = yelp_class['text']  # text column

y = yelp_class['stars']  # star column

# Text pre-processing

import string


def pre_process(text):
    """
        Takes in a string of text, then performs the following:
        1. Remove all punctuation
        2. Remove all stopwords
        3. Return the cleaned text as a list of words
        """

    nopunc = [char for char in text if char not in string.punctuation]

    nopunc = ''.join(nopunc)

    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]


"""
sample_text = "Hey there! This is a sample review, which happens to contain punctuations."

print(pre_process(sample_text))
"""

# vectorization

from sklearn.feature_extraction.text import CountVectorizer

bow_transformer = CountVectorizer(analyzer=pre_process).fit(x)
review_25 = x[24]

print(review_25)

bow_25 = bow_transformer.transform([review_25])

print(bow_25)

x = bow_transformer.transform(x)

print('Shape of Sparse Matrix: ', x.shape)
print('Amount of Non-Zero occurrences: ', x.nnz)

# Percentage of non-zero values

density = (100.0 * x.nnz / (x.shape[0] * x.shape[1]))
print('Density: {}'.format((density)))

# training

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)

from sklearn.naive_bayes import MultinomialNB

nb = MultinomialNB()
nb.fit(x_train, y_train)

# testing

preds = nb.predict(x_test)

from sklearn.metrics import confusion_matrix, classification_report

print(confusion_matrix(y_test, preds))
print('\n')
print(classification_report(y_test, preds))

# Predicting a singular positive review

positive_review = yelp_class['text'][59]
positive_review_transformed = bow_transformer.transform([positive_review])
print(nb.predict(positive_review_transformed)[0])
